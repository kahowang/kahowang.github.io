<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Projects | Academic</title>
    <link>https://example.com/project/</link>
      <atom:link href="https://example.com/project/index.xml" rel="self" type="application/rss+xml" />
    <description>Projects</description>
    <generator>Wowchemy (https://wowchemy.com)</generator><language>en-us</language>
    <image>
      <url>https://example.com/media/icon_hu0b7a4cb9992c9ac0e91bd28ffd38dd00_9727_512x512_fill_lanczos_center_3.png</url>
      <title>Projects</title>
      <link>https://example.com/project/</link>
    </image>
    
    <item>
      <title>FASTLIO-SAM</title>
      <link>https://example.com/project/example/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/example/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://wudiguang.top/images/hexo/gallery/1.jpg&#34; alt=&#34;&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;b style=&#34;font-family: Arial, sans-serif;&#34;&gt;Mask Task&lt;/b&gt;:
Built a complete SLAM mapping system (data preprocessing, front-end odometry, back-end optimization, loop detection) and successfully deployed it on a robot.&lt;/p&gt;
&lt;p&gt;*Front-end odometry:
Implemented a 30ms update rate front-end odometry using the Kalman gain update method from &amp;ldquo;FAST-LIO2&amp;rdquo; and the use of ikdtree (balanced binary tree) reference.&lt;/p&gt;
&lt;p&gt;*Back-end optimization:
Used the GTSAM factor graph optimization library based on ISAM2 to fuse Lidar, IMU, and RTK data, achieving global optimization of indoor and outdoor poses.&lt;/p&gt;
&lt;p&gt;*Loop detection:
Used both Euclidean distance-based loop detection and ScanContext-based global descriptor loop detection methods. Loop detection was performed in an independent thread, and the overall mapping process was parallel in structure, with a low frequency loop retrieval rate.&lt;/p&gt;
&lt;p&gt;*Accuracy evaluation:
Tested on public datasets both indoors and outdoors. For indoor testing data, the algorithm was able to significantly eliminate map shadow and height error compared to FASTLIO2. For outdoor testing data, the calculated trajectory and RTK positioning results were unified in the ENU coordinate system and evaluated with EVO trajectory error assessment, with an RMSE of 0.3m.&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>High precision map automation lane vectorization</title>
      <link>https://example.com/project/high/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/high/</guid>
      <description>&lt;p&gt;&lt;b style=&#34;font-family: Arial, sans-serif;&#34;&gt;  Based on the Mask2Former network, semantic segmentation was performed on the image data, and 3D lane line point clouds were extracted through the camera and LiDAR extrinsics. Finally, the 3D lane lines were clustered and curve-fitted, achieving high-precision map automatic vectorization of lane lines.&lt;/b&gt;&lt;/p&gt;
&lt;p&gt;&lt;b style=&#34;font-family: Arial, sans-serif;&#34;&gt;  Our manual handle data record platform&lt;/b&gt;:&lt;br&gt;
In order to quickly verify the algorithm , we built our owndata record platfor(handle &amp;amp; package). After many iterations, now out platform can compatibility a variety of lidar(Tested：Hesai32、Robosense32、Livox mid70&amp;hellip;), IMU(Tested: Xsens mti710、Lpms ig1) and camera(Hikvision、Intel D435i). We also carried out hardware synchronization and external parameter calibration on our equipment.&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/lane_vectorization%20/%E8%83%8C%E5%8C%85%E9%9B%B7%E8%BE%BE.gif&#34; width=&#34;48%&#34; style=&#34;display:inline-block&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/lane_vectorization%20/%E6%89%8B%E6%8C%81%E9%9B%B7%E8%BE%BE.gif&#34; width=&#34;46%&#34; style=&#34;display:inline-block&#34;&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;   &lt;p&gt;manual data record platform&lt;/p&gt; &lt;/div&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/lane_vectorization%20/%E4%BC%A0%E6%84%9F%E5%99%A8%E7%A1%AC%E4%BB%B6%E5%90%8C%E6%AD%A5.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;   &lt;p&gt;pps hardware synchronization&lt;/p&gt; &lt;/div&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/lane_vectorization%20/%E5%A4%96%E5%8F%82%E6%A0%87%E5%AE%9A1.png&#34; width=&#34;43%&#34; style=&#34;display:inline-block&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/lane_vectorization%20/%E6%A0%87%E5%AE%9A%E7%BB%93%E6%9E%9C%E5%B1%95%E7%A4%BA.png&#34; width=&#34;48%&#34; style=&#34;display:inline-block&#34;&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;   &lt;p&gt;Automatic calibration of external parameters&lt;/p&gt; &lt;/div&gt;
&lt;p&gt;&lt;b style=&#34;font-family: Arial, sans-serif;&#34;&gt;Mapping&lt;/b&gt;:&lt;/p&gt;
&lt;p&gt;Based on FASTLIO-SAM .Construct pointcloud map, area：1km&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/lane_vectorization%20/%E7%82%B9%E4%BA%91%E5%9C%B0%E5%9B%BE2.gif&#34; width=&#34;46%&#34; style=&#34;display:inline-block&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/lane_vectorization%20/%E7%82%B9%E4%BA%91%E5%9C%B0%E5%9B%BE1.gif&#34; width=&#34;48%&#34; style=&#34;display:inline-block&#34;&gt;
&lt;/div&gt;
&lt;p&gt;&lt;b style=&#34;font-family: Arial, sans-serif;&#34;&gt;Color Mapping&lt;/b&gt;:&lt;/p&gt;
&lt;p&gt;RGB Pointcloud map is constructed through the external parameters of the camera and lidar&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/lane_vectorization%20/rbg%E4%B8%8A%E8%89%B2%E5%9B%BE2.gif&#34; width=&#34;46%&#34; style=&#34;display:inline-block&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/lane_vectorization%20/%E4%B8%8A%E8%89%B2%E6%B7%B1%E5%A4%A7%E8%BD%A6%E9%81%93%E7%BA%BF.gif&#34; width=&#34;48%&#34; style=&#34;display:inline-block&#34;&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/lane_vectorization%20/FASTLIO-COLOR.gif&#34; width=&#34;48%&#34; style=&#34;display:inline-block&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/lane_vectorization%20/FASTLIO-COLOR2.gif&#34; width=&#34;48%&#34; style=&#34;display:inline-block&#34;&gt;
&lt;/div&gt;
&lt;p&gt;&lt;b style=&#34;font-family: Arial, sans-serif;&#34;&gt;Semantic Map&lt;/b&gt;:&lt;/p&gt;
&lt;p&gt;Semantic Pointcloud map is constructed through the external parameters of the camera and lidar&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/lane_vectorization%20/2d%E8%AF%AD%E4%B9%89.gif&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;   &lt;p&gt;Road semantic segmentation based on Mask2Former model&lt;/p&gt; &lt;/div&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/lane_vectorization%20/%E8%AF%AD%E4%B9%89%E5%9C%B0%E5%9B%BE.gif&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;   &lt;p&gt;3D Semantic Map&lt;/p&gt; &lt;/div&gt;
&lt;p&gt;&lt;b style=&#34;font-family: Arial, sans-serif;&#34;&gt;Extraction of ground elements&lt;/b&gt;:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/lane_vectorization%20/%E6%8F%90%E5%8F%96%E8%B7%AF%E9%9D%A2%E8%AF%AD%E4%B9%89%E4%BF%A1%E6%81%AF.gif&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;&lt;b style=&#34;font-family: Arial, sans-serif;&#34;&gt;Lane vectorization&lt;/b&gt;:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/lane_vectorization%20/%E8%BD%A6%E9%81%93%E7%BA%BF%E7%9F%A2%E9%87%8F%E5%8C%96.gif&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/lane_vectorization%20/%E8%BD%A6%E9%81%93%E7%BA%BF%E7%9F%A2%E9%87%8F%E5%8C%96%E8%93%9D%E8%89%B2.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
</description>
    </item>
    
    <item>
      <title>Large scale mapping</title>
      <link>https://example.com/project/laege/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/laege/</guid>
      <description>&lt;p&gt;&lt;b style=&#34;font-family: Arial, sans-serif;&#34;&gt;Large range (5km*5km) point cloud map construction, front-end method is FASTLIO2, back-end optimization using ISAM2&lt;/b&gt;:&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/large_map/image76.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;   &lt;p&gt;before optimization&lt;/p&gt; &lt;/div&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/large_map/image8.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;   &lt;p&gt;after optimization&lt;/p&gt; &lt;/div&gt;
</description>
    </item>
    
    <item>
      <title>Ollie ball balancing</title>
      <link>https://example.com/project/external-project/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/external-project/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/ollie/%E6%9C%A8%E7%90%83.gif&#34; width=&#34;45%&#34; style=&#34;display:inline-block&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/ollie/%E5%A4%9A%E7%90%83.gif&#34; width=&#34;45%&#34; style=&#34;display:inline-block&#34;&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/ollie/%E6%9C%A8%E7%90%83%E4%B8%8B%E5%8F%B0%E9%98%B6.gif&#34; width=&#34;45%&#34; style=&#34;display:inline-block&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/ollie/%E6%9C%A8%E7%90%83%E8%BF%87%E5%9D%A1.gif&#34; width=&#34;45%&#34; style=&#34;display:inline-block&#34;&gt;
&lt;/div&gt;
&lt;p&gt;&lt;b style=&#34;font-family: Arial, sans-serif;&#34;&gt;Robot&lt;/b&gt;:&lt;br&gt;
Ollie is a wheel-legged robot developed by Tencent and another innovative exploration of Tencent Robotics X Robotics Lab after Jamoca and Max. It integrates a number of leading motion control technologies and makes key breakthroughs in motion planning, balance and stability, human-computer interaction and other fields.&lt;/p&gt;
&lt;p&gt;&lt;b style=&#34;font-family: Arial, sans-serif;&#34;&gt;BackGround&lt;/b&gt;:&lt;br&gt;
Tencent Robotics X Robotics Lab combines tactile sensors with Ollie, a wheel-legged robot, in an innovative way.With the support of the sense of touch and the stable movement ability, Ollie can also challenge the difficult tasks of balancing the head and carrying spherical objects. By making full use of the contact information between the sphere and the robot surface, combined with the data of its own attitude sensor and the joint motor encoder, Ollie realizes the perfect combination of the upper body object control ability and the lower body movement balance ability.&lt;/p&gt;
&lt;p&gt;&lt;b style=&#34;font-family: Arial, sans-serif;&#34;&gt;Main Tasks&lt;/b&gt;:&lt;br&gt;
Based on the unique characteristics of the foot-wheel and linkage structure of the underactuated wheeled-legged robot, we fine-tuned the Whole-Body Control (WBC) algorithm to achieve the robot&amp;rsquo;s self-balancing and high-dynamic performance. Combined with feedback signals from our self-developed tactile sensors, we realized the robot&amp;rsquo;s ball-balancing and carrying capabilities.&lt;/p&gt;
&lt;p&gt;&lt;b style=&#34;font-family: Arial, sans-serif;&#34;&gt;Robot Simulation&lt;/b&gt;:&lt;br&gt;
We utilized the Gazebo simulation platform to perform dynamic simulation of the robot, as well as to simulate feedback signals from tactile sensors.&lt;/p&gt;
&lt;p&gt;&lt;b style=&#34;font-family: Arial, sans-serif;&#34;&gt;Data Processing&lt;/b&gt;:&lt;br&gt;
Apply Kalman filtering to process data from our self-developed tactile sensor, and return the results in the form of a ROS point cloud.&lt;/p&gt;
&lt;p&gt;&lt;b style=&#34;font-family: Arial, sans-serif;&#34;&gt;Some Videos:&lt;/b&gt;:&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;   &lt;p&gt;Ollie Ball Balancing&lt;/p&gt; &lt;/div&gt;
&lt;iframe src=&#34;//player.bilibili.com/player.html?aid=430339657&amp;bvid=BV1KG411V7Mv&amp;cid=827806337&amp;page=1&#34; scrolling=&#34;no&#34; border=&#34;0&#34; frameborder=&#34;no&#34; framespacing=&#34;0&#34; allowfullscreen=&#34;true&#34; width = 800 height = 500 &gt; &lt;/iframe&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;   &lt;p&gt;Ollie Ball First Show&lt;/p&gt; &lt;/div&gt;
&lt;iframe src=&#34;//player.bilibili.com/player.html?aid=460892143&amp;bvid=BV1g5411M784&amp;cid=348289079&amp;page=1&#34; scrolling=&#34;no&#34; border=&#34;0&#34; frameborder=&#34;no&#34; framespacing=&#34;0&#34; allowfullscreen=&#34;true&#34; width = 800 height = 500  &gt; &lt;/iframe&gt;</description>
    </item>
    
    <item>
      <title>Robot Fast Relocalization Initialization</title>
      <link>https://example.com/project/localiazion/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/localiazion/</guid>
      <description>&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/relocalization/eskf.gif&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;   &lt;p&gt;ESKF Localization&lt;/p&gt; &lt;/div&gt;
&lt;p&gt;&lt;b style=&#34;font-family: Arial, sans-serif;&#34;&gt;Localization&lt;/b&gt;:&lt;/p&gt;
&lt;p&gt;Based on ESKF localization . Measurement factors include Wheel encoder , RTK , and PointCloud matching. Prediction factors include IMU Inertial calculation.&lt;/p&gt;
&lt;p&gt;&lt;b style=&#34;font-family: Arial, sans-serif;&#34;&gt;ReLocalization Initialization&lt;/b&gt; :&lt;/p&gt;
&lt;p&gt;The position information is provided by the single point gnss, the initialization yaw  is provided by ScanConext matching, and the precise matching is performed by ICP .&lt;/p&gt;
&lt;p&gt;















&lt;figure  &gt;
  &lt;div class=&#34;d-flex justify-content-center&#34;&gt;
    &lt;div class=&#34;w-100&#34; &gt;&lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/relocalization/framework.png&#34; alt=&#34;img&#34; loading=&#34;lazy&#34; data-zoomable /&gt;&lt;/div&gt;
  &lt;/div&gt;&lt;/figure&gt;
&lt;/p&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;   &lt;p&gt;ScanContext Fast ReLocalization Initialization Framework&lt;/p&gt; &lt;/div&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/relocalization/iter1.gif&#34; width=&#34;45%&#34; style=&#34;display:inline-block&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/relocalization/iter2.gif&#34; width=&#34;45%&#34; style=&#34;display:inline-block&#34;&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;   &lt;p&gt;
Use scancontext descriptor for 360 degree point cloud matching &lt;/p&gt; &lt;/div&gt;
&lt;b style=&#34;font-family: Arial, sans-serif;&#34;&gt;Some Videos:&lt;/b&gt;: 
&lt;div style=&#34;text-align:center;&#34;&gt;   &lt;p&gt;ESKF Localization&lt;/p&gt; &lt;/div&gt;
&lt;iframe src=&#34;//player.bilibili.com/player.html?aid=851260048&amp;bvid=BV1FL4y1s75L&amp;cid=500973981&amp;page=1&#34; scrolling=&#34;no&#34; border=&#34;0&#34; frameborder=&#34;no&#34; framespacing=&#34;0&#34; allowfullscreen=&#34;true&#34; width = 800 height = 500&gt; &lt;/iframe&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;   &lt;p&gt;Relocalization Initialization base on ScanContext&lt;/p&gt; &lt;/div&gt;
&lt;iframe src=&#34;//player.bilibili.com/player.html?aid=681318528&amp;bvid=BV1NS4y1G7gi&amp;cid=500958420&amp;page=1&#34; scrolling=&#34;no&#34; border=&#34;0&#34; frameborder=&#34;no&#34; framespacing=&#34;0&#34; allowfullscreen=&#34;true&#34; width = 800 height = 500 &gt; &lt;/iframe&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;   &lt;p&gt;Localization Visual on Mapviz&lt;/p&gt; &lt;/div&gt;
&lt;iframe src=&#34;//player.bilibili.com/player.html?aid=756801932&amp;bvid=BV1qr4y1N7Lf&amp;cid=302373053&amp;page=1&#34; scrolling=&#34;no&#34; border=&#34;0&#34; frameborder=&#34;no&#34; framespacing=&#34;0&#34; allowfullscreen=&#34;true&#34; width = 800 height = 500&gt; &lt;/iframe&gt;</description>
    </item>
    
    <item>
      <title>Robots Related to me</title>
      <link>https://example.com/project/some-robots/</link>
      <pubDate>Mon, 01 Jan 0001 00:00:00 +0000</pubDate>
      <guid>https://example.com/project/some-robots/</guid>
      <description>&lt;div style=&#34;text-align:center;&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/lane_vectorization%20/%E8%83%8C%E5%8C%85%E9%9B%B7%E8%BE%BE.gif&#34; width=&#34;48%&#34; style=&#34;display:inline-block&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/lane_vectorization%20/%E6%89%8B%E6%8C%81%E9%9B%B7%E8%BE%BE.gif&#34; width=&#34;46%&#34; style=&#34;display:inline-block&#34;&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;   &lt;p&gt;Manual Handle data record platform&lt;/p&gt; &lt;/div&gt;
In order to quickly verify the algorithm , we built our owndata record platfor(handle &amp; package). After many iterations, now out platform can compatibility a variety of lidar(Tested：Hesai32、Robosense32、Livox mid70...), IMU(Tested: Xsens mti710、Lpms ig1) and camera(Hikvision、Intel D435i). We also carried out hardware synchronization and external parameter calibration on our equipment.
&lt;div style=&#34;text-align:center;&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/some-robots/jackal.jpeg&#34; width=&#34;35%&#34; style=&#34;display:inline-block&#34;&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;   &lt;p&gt; 3D slam platform for Wheeled robot&lt;/p&gt; &lt;/div&gt;
It is composed of  Lidar, IMU, RTK, Encoder and Jackal chassis. It is applied to the fast slam algorithm verification.
&lt;div style=&#34;text-align:center;&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/some-robots/ollie.GIF&#34; width=&#34;55%&#34; style=&#34;display:inline-block&#34;&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;   &lt;p&gt; Wheeled Bipedal Robot Ollie&lt;/p&gt; &lt;/div&gt;
Design by Tencent Robotics X，based on WBC and Nonlinear control.
&lt;div style=&#34;text-align:center;&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/some-robots/robike.png&#34; width=&#34;55%&#34; style=&#34;display:inline-block&#34;&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;   &lt;p&gt; Self-balancing bicycle robike&lt;/p&gt; &lt;/div&gt;
Design by Tencent Robotics X，based on Gain Scheduling Controller.
&lt;div style=&#34;text-align:center;&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/some-robots/%E6%AF%AB%E6%9C%AB.png&#34; width=&#34;55%&#34; style=&#34;display:inline-block&#34;&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;   &lt;p&gt;Haomo.ai HDeliver &#34;小魔驼&#34; &lt;/p&gt; &lt;/div&gt;
Haomo.ai&#39;s HDeliver &#34;小魔驼&#34;， L4 driverless delivery vehicle.
&lt;div style=&#34;text-align:center;&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/some-robots/%E5%93%A8%E5%85%B5.png&#34; width=&#34;40%&#34; style=&#34;display:inline-block&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/some-robots/%E8%8B%B1%E9%9B%84.png&#34; width=&#34;39%&#34; style=&#34;display:inline-block&#34;&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;   &lt;p&gt;RoboMaster &lt;/p&gt; &lt;/div&gt;
From 2017 to 2019, as the captain of the IMCA Robotics Team at Wuyi University, I participated in robotics competitions and was mainly responsible for embedded development and intelligent recognition.
&lt;div style=&#34;text-align:center;&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/some-robots/%E5%93%A8%E5%85%B5.gif&#34;&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;   &lt;p&gt;Automatic shooting robot &lt;/p&gt; &lt;/div&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;
  &lt;img src=&#34;https://kaho-pic-1307106074.cos.ap-guangzhou.myqcloud.com/academic_website_pic/some-robots/%E5%B7%A5%E7%A8%8B%E8%BD%A6.gif&#34; width=&#34;50%&#34;&gt;
&lt;/div&gt;
&lt;div style=&#34;text-align:center;&#34;&gt;   &lt;p&gt;Engineering grab robot &lt;/p&gt; &lt;/div&gt;</description>
    </item>
    
  </channel>
</rss>
